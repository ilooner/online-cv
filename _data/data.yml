#
# Be aware that even a small syntax error here can lead to failures in output.
#

sidebar:
    about: False # set to False or comment line if you want to remove the "how to use?" in the sidebar
    education: True # set to False if you want education in main section instead of in sidebar

    # Profile information
    name: Timothy Farkas
    tagline: Backend Engineer
    avatar: profile.jpg  #place a 100x100 picture inside /assets/images/ folder and provide the name of the file below

    # Sidebar links
    email: timothytiborfarkas@gmail.com
    website: ilooner.github.io/online-cv/
    linkedin: timothy-farkas-a8554645
    github: ilooner
    gitlab:
    bitbucket:
    stack-overflow: 3811080/ilooner
    codewars:

education:
    - degree: BS in Electrical and Computer Engineering
      university: Carnegie Mellon University
      time: 2008 - 2012
      details:

    - degree: BS in Mathematics
      university: Carnegie Mellon University
      time: 2008 - 2012
      details:

    - degree: Minor in Computer Science
      university: Carnegie Mellon University
      time: 2008 - 2012
      details:

experiences:
    - role: Senior Software Engineer
      time: June 2019 - Present
      company: Netflix
      details: |
        Work on RDE (Realtime Data Engines)

          - RDE is the uber team comprised of the Kafka and Flink subteams. Have been oncall for both Flink and Kafka infrastructure.
            And provided user support for both platforms.
          - Co-designed strategy for a large scale migration of several thousand Flink jobs from
            a legacy control plane to the new RDE Flink control plane.
          - Worked on a team to successfully execute the migration without user job disruption and
            without data loss.
          - Implemented automated topic mapping for producers, which allows producers to automatically discover the kafka cluster
            their data needs to be published to.
          - Implemented automated topic move, which allows topics to be seamless moved to a new cluster without disrupting producers
            or consumers.

        Work on Kafka Team

          - Operated the Kafka control plane, which manages all of Netflix's Kafka clusters.
          - Implemented cluster metadata improvements for the Kafka control plane.
          - Implemented authorization bug fixes for Netflix's Kafka fork.
          - Planned and executing migration from non-secure kafka clusters to secure kafka clusters.

        Work on Flink Team

          - Operated the Flink control plane, which manages thousands of production Flink jobs.
          - Implemented numerous bugfixes and improvements for Netflix's Flink fork, Netflix's internal Flink library, and the Flink control plane.
          - Optimized Netflix's internal Avro serialization and deserialization libraries to get more than a 100x performance improvement.
          - Integrated Netflix's avro serialization and deserialization libraries with Flink.
          - Worked with our largest user to migrate their large stateful Flink jobs with 800+ cpus each from JSON to AVRO. After
            migrating to Avro, job state size and number of cpus was cut in half, resulting in a large cost savings.
          - Implemented robust autoscaling for thousands of Flink jobs in production.
            This has been running in production for several years. Reduced oncall burden and
            yielded a large yearly cost savings.
          - [LinkedIn Engineering autoscaling talk](https://www.youtube.com/watch?v=vksWF8UgWXc)
          - [Flink Forward atuoscaling talk](https://www.youtube.com/watch?v=NV0jvA5ZDNc&t=755s)
    - role: Senior Staff Software Engineer
      time: Apr 2019 - June 2019
      company: MapR Technologies, San Jose, CA
    - role: Staff Software Engineer
      time: Aug 2017 - Apr 2019
      company: MapR Technologies, San Jose, CA
      details: |
        Work on MapR Cloud

          - Designed and created a service to deploy, manage, and access MapR clusters in the cloud.
            Evaluated AWS, Azure, and GCP across multiple dimensions to pick the cloud with the highest ROI to
            launch the service on. Met with members of the Azure cloud team and AKS (Azure Kubernetes Service).
          - Deployed on Azure with AKS (Azure Kuber).
          - Designed security model to allow remote access to the MapR cluster through
            the browser for users.
          - Designed security model for operators to manage the clusters.

        Work on Drill

          - Started the resource management project for concurrent queries on Drill.
          - Worked on operator spilling when processing large data sets.
          - Fixed race conditions and memory leaks in the execution engine.
          - General refactoring work to improve project testability, build stability, and maintainability.
    - role: Apache Drill Committer
      time: May 2018 - Present
      company: The Apache Software Foundation
      details: |
        Committer for Apache Drill.

    - role: Apache Apex Committer
      time: Jun 2015 - Present
      company: The Apache Software Foundation
      details: |
        Committer for Apache Apex.

    - role: Software Engineer
      time: Dec 2016 - Aug 2017
      company: GE Digital, San Ramon, CA
      details: |
        Built a scalable and fault-tolerant lambda function service similar to AWS Lambda from scratch.

          - Built the engine on top of Apache Mesos and wrote it in Go.
          - Utilized docker for secure execution of lambda functions.
          - The engine supported realtime stream processing.
          - Created some Go helper libraries for dependency injection and writing Spring style Rest APIs.

    - role: Principal Software Engineer
      time: Apr 2016 - Dec 2016
      company: Logichub, Mountain View, CA
      details: |
        Worked on a automated cyber security threat detection platform.

          - Co-designed and developed a data processing platform on top of Apache Spark.
          - Designed and implemented domain specific data caching and data provenance algorithms.
          - Used the Scala Play REST framework.
          - Wrote various spark jobs.

    - role: Software Engineer
      time: Aug 2014 - Apr 2016
      company: DataTorrent, San Jose, CA
      details: |
        Worked on Apache Apex, a real-time stream processing platform built on top of Hadoop.

          - Implemented critical POCs for potential customers
          - Fixed bugs and added features to Apache Apex and Apache Apex Malhar
          - Built a data aggregation and visualization engine on top of Apache Apex, which was used in production.
          - Co-designed and authored App Data Tracker, which is an Apex application that allows users to collect, aggregate, and visualize metrics published by other apps on their cluster.

    - role: Software Engineer
      time: Jul 2012 - Aug 2014
      company: Oracle, Santa Clara, CA
      details: |
        - Designed and implemented a benchmark analysis system which handled hundreds of millions of data points.
        - Wrote an agent that collected benchmark results generated by other teams.
        - Built a backend server on top of Glassfish which stored and queried results from Mysql.
        - Built a front end in Java Swing.
        - Designed a search algorithm which allowed the user to navigate the sparse high-dimensional data set.
        - Used the tool to catch critical performance regressions before they hit customers.
        - Maintained various pieces of infrastructure: internal website, wiki, solaris package server.

    - role: Data Coder
      time: Nov 2009 - Sep 2011
      company: CASOS, Pittsburgh, PA
      details: |
        - Designed and implemented a user friendly drag and drop interface, which allowed users of CASOS's Automap system to easily create script files that are executable by Automap. The interface is available for download as part of the Automap package at [http://www.casos.cs.cmu.edu/projects/automap/software.php](http://www.casos.cs.cmu.edu/projects/automap/software.php). The program can be accessed by launching Automap, going to the tools menu, and selecting script runner.
        - Maintained and augmented a large body of code (Automap's script library).
        - Designed and created an inter-process logging system based on log4j and integrated it with the Automap code base.
        - Implemented many small special purpose programs and user interfaces.

